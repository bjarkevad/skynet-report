\documentclass[Main]{subfiles}
\begin{document}

The planning problem was approached from two different angles, that were intended to be merged later. The two approaches were partial order planning and hierarchical task network. "[!Ref:]" 


\subsection{POP}

\textbf{Experimenting with back-tracking}

It was attempted to implement a back-tracking algorithm ....

\todo{Emil}





\subsection{HTN}
As part of the development a simple HTN algorithm for solving levels were developed for single agent scenarios.
The algorithm used a genetic algorithm to calculate an optimal order in which to solve the goals.
The motivation for using a genetic algorithm, is that the problem of finding an optimal route to move a set of boxes to a set of goals, can be seen as a traveling salesman problem which is an np-complete task that genetic algorithms can help generate a solution for.
Genetic algorithms cannot calculate the most optimal order, but it can come up with a relative good suboptimal solution in a timely manner. The genetic algorithm used for the HTN experiments is inspired by the implementation at \cite{genetic}.

The genetic algorithm basically works by creating a population which is a list of lists where the inner lists are random permutations of all goals to be completed, next the outer list is sorted using an evaluation function that calculates the travel time to complete a given permutation of goals. The algorithm now mutates and shuffles some of the population by using parts from the best performing permutations. This goes on until the algorithm doesn't seem to produce good results anymore.

The HTN implementation itself, works by taking an ordered set of goals to be completed as input. Then the first goal is chosen and the algorithm decomposes a complex action to move to the box, where only move actions are considered. When primitive move actions to the goal has been generated, it calculates the needed primitive actions to move the box to the goal, where all possible actions are considered in the progress. The algorithm uses the A\^{*} algorithm to decompose into the primitive goals.
This can be seen as decomposing a complex action CompleteSubGoal into MoveToBox and MoveBoxToGoal and finally into primitive actions for completing the goal.
When the algorithm starts, it only takes the first box for the first goal into account and the rest act as obstacles. When a goal has been completed, the current box remains visible and no longer acts as an obstacle, and can thus still be manipulated. This reduces the branching factor when solving the individual goals, in the beginning, but adds more and more branching factor towards the completion of the unified plan.

In the end, the HTN algorithm was discarded because the POP algorithm was performing a lot better and it was chosen to focus on the POP algorithm.




\subsection{General} 


\textbf{Experimenting with heuristics}

- Weighted heuristics to encourage specific moves

The heuristics for the full problem search is a simple heuristic calculating the Manhattan distance between the active elements of a node. The active elements being an agent, a goal and a box chosen to solve the goal with. 




\textbf{Experiments with search strategy}

\begin{enumerate}
    \item BFS 
    \item Multi queue BFS (Maybe IDA* or Iterative deepening search)
\end{enumerate}



Benchmarking the multi queue BFS against standard BFS:





\subsection{Preprocessing ----- "??????" }

Experimenting with preprocessing and ``All goals shortest path'' 
- Part of the POP algorithm

- POP run after each solved goal 
--> Better solution --> SO much slower


During development experiments with different strategies regarding preprocessing, or extra-processing providing extra information, were conducted. 

As for the goal ordering based on a relaxed problem search on the initial state, the information about the level at this state is very useful. It is, however, preferred to have the same updated information after each solved goal. The moving of one or more boxes, and the change of the agent's location, will most likely leave the goal sorting less than optimal. It could therefore be beneficial to update the goal sorting, and maybe even the choosing of boxes for goals. 

In order to update the information a relaxed problem search is done based on the state after each goal is solved. 


- Performance affected by number of goals and agents in level, if few, maybe beneficial, if many it could produce a lot of overhead.






\subsection{Results}




\end{document}